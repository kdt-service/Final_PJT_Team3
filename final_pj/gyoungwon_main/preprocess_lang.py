# import sys
# sys.path.append('/home/ubuntu/final_pj') # ê°™ì€ ì„ ìƒì— ìˆëŠ” íŒŒì¼ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—
# from crawling_funcs import *
# from extra_funcs import *
# from db_connect import * 
# from video_list import *
# from recent_highview_list import * 

# ì—¬ê¸°ì„œ ì‚¬ìš© ì•ˆí•˜ëŠ” íŒ¨í‚¤ì§€ë“¤ì´ë¼ ì£¼ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.

import pandas as pd
import re
import emoji #ec2 ì„¤ì¹˜ì™„ë£Œ
from soynlp.normalizer import *
import langid #ec2 ì„¤ì¹˜ì™„ë£Œ
import plotly.express as px

# ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocessing(df):

    def process_text(text):
        result = re.sub('(?=\<a).+(?<=a>)', '' , text) # aíƒœê·¸ ì œê±°
        result = re.sub('(?=\<b).+(?<=b>)', '' , text) # bíƒœê·¸ ì œê±°
        result = re.sub('(<br>)+', '' , result) # <br>íƒœê·¸ ì œê±°
        result = re.sub('[\n\t]', ' ', result) # ì¤„ë°”ê¿ˆ, í… -> ë„ì–´ì“°ê¸°ë¡œ ëŒ€ì²´
        result = re.sub('(&quot;)', '' , result) # &quot; ì œê±°
        result = re.sub(r'@[^ ]*', '', result) # ë‹µëŒ“ê¸€ì‹œ @ë‹‰ë„¤ì„ ì œê±°
        
        result = emoticon_normalize(result, num_repeats=2)  # ì´ëª¨ì§€, íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        result = repeat_normalize(result, num_repeats=2)
        
        return result.strip()

    #df = pd.read_csv(file_path) # íŒŒì¼ ìœ„ì¹˜ ì½ê¸°
    df.dropna(inplace=True) # nan value ìˆëŠ” í–‰ ì œê±°
    df.drop_duplicates(inplace=True) #ì¤‘ë³µ í–‰ ì œê±° 
    df = df[df['content'].str.len() > 1] # ëŒ“ê¸€ ê¸¸ì´ê°€ í•œ ê¸€ìë©´ ì œê±°
    df['processed_content'] = df['content'].apply(process_text)
    
    emoji_text = ''.join(set(list(emoji.EMOJI_DATA.keys()))) # ì´ëª¨ì§€ ë°ì´í„°

    #â™¥ â™¡ .!,? ì œì™¸í•œ íŠ¹ìˆ˜ë¬¸ìì™€ ì¼ë°˜ë¬¸ì ìˆ˜ ë¹„êµ í›„ íŠ¹ìˆ˜ë¬¸ì ë” ë§ì„ ì‹œ í•´ë‹¹ ëŒ“ê¸€ ì œê±°
    indices_to_drop = []  # ì œê±°í•  ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    
    for i, content in enumerate(df['processed_content']):
        normal_text = len(re.findall(f'[\w\s\{emoji_text}\â™¥ â™¡ .!,?]', content))
        special_text = len(re.findall(f'[^\w\s\{emoji_text}\â™¥ â™¡ .!,?]', content))

        if normal_text >= special_text:
            pass
        else:
            indices_to_drop.append(i)

    df = df.drop(indices_to_drop).reset_index(drop=True)

    #emoji, íŠ¹ìˆ˜ë¬¸ìë¡œ êµ¬ì„±ëœ ëŒ“ê¸€ etcë¡œ í•„í„°ë§(ì¶”í›„ì— kcelectra ê°ì„± ë¶„ë¥˜)
    for i, content in enumerate(df['processed_content']):
        if re.search(rf'^(?:[^\w\s]|{emoji_text})+$', content):
            df.loc[i, 'lang'] = 'etc'
            
    # ì–¸ì–´ íŒë³„ ëª¨ë“ˆ ì •í™•ë„ ë†’ì´ê¸° ìœ„í•˜ì—¬ emoji, íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ì–¸ì–´íŒë³„ìš© ì¹¼ëŸ¼ì¸ for_langidì— í• ë‹¹
    df['for_langid'] = df['processed_content'].apply(lambda x: re.sub(rf'([^\w\s]|{emoji_text})', '', x))

    return df


# ì–¸ì–´ ë¶„ë¥˜ í•¨ìˆ˜
def identify_lang(df):
    df['lang'] = df.apply(lambda row: langid.classify(row['for_langid'])[0], axis=1) #langid ì‚¬ìš©í•˜ì—¬ ëŒ“ê¸€ ì–¸ì–´ íŒë³„ 

    # ë”°ë¡œ ì²˜ë¦¬í•˜ê² ìŒ
    # df = df[df['lang'].isin(['en', 'ko', 'etc'])] # langì— en, ko, etc ê°€ ì•„ë‹Œ í–‰ì€ ë‹¤ ì‚­ì œí•˜ê¸°
    df = df.drop('for_langid', axis=1) #for_langid ì‚­ì œ

    #ì•ŒíŒŒë²³, í•œê¸€ ìˆ˜ ë¹„êµ í›„ í•œê¸€ì´ ë” ë§ìœ¼ë©´ ko, ì˜ì–´ê°€ ë” ë§ìœ¼ë©´ enë¡œ ì¬ë¶„ë¥˜
    for i, content in df[df['lang'].isin(['en', 'ko'])]['processed_content'].items():
        kor_text = len(re.findall('[ã„±-ã…ê°€-í£ã…-ã…£]', content))
        eng_text = len(re.findall('[A-Za-z]', content))
    
        if kor_text >= eng_text:
            df.loc[i, 'lang'] = 'ko'
        else:
            df.loc[i, 'lang'] = 'en'

    for i, content in df[df['lang'].isin(['ja'])]['processed_content'].items():
       # ì¼ë³¸ì–´ë¡œ ë¶„ë¥˜ëœ ëŒ“ê¸€ë“¤ (ã…‹ã…‹ã…‹ã…‹, ã…‡ã…ˆ ìœ¼ë¡œ êµ¬ì„±ëœ ëŒ“ê¸€ ë§ìŒ) í•œêµ­ì–´ë¡œ ì¬ë¶„ë¥˜ 
        kor_text = len(re.findall('[ã„±-ã…ê°€-í£ã…-ã…£]', content))
        eng_text = len(re.findall('[A-Za-z]', content))
        jap_text = len(re.findall('[ã-ã‚”]+|[ã‚¡-ãƒ´ãƒ¼]+[ã€…ã€†ã€¤]', content))
        text = len(content)
        if kor_text >= text*0.5: # ì ˆë°˜ì´ìƒì´ í•œê¸€ì´ë©´ 
            df.loc[i, 'lang'] = 'ko'
          
        if jap_text == 0 : # ì¼ë³¸ì–´ê°€ ì—†ì–´ (ì˜ì–´, í•œê¸€ ì„ì—¬ ìˆëŠ” ê²½ìš° ì¡´ì¬)
          if kor_text >= eng_text:
            df.loc[i, 'lang'] = 'ko'
          else:
            df.loc[i, 'lang'] = 'en'

    for i, content in df[df['lang'].isin(['zh'])]['processed_content'].items(): # ì¤‘êµ­ì–´ë¡œ ë¶„ë¥˜ëœ ëŒ“ê¸€ ì¤‘ì—ì„œ í•œê¸€ ì°¾ê¸°
        kor_text = len(re.findall('[ã„±-ã…ê°€-í£ã…-ã…£]', content))
        text = len(content)
        if kor_text >= text*0.5: # ì ˆë°˜ì´ìƒì´ í•œê¸€ì´ë©´ 
            df.loc[i, 'lang'] = 'ko'
            
    for i in range(len(df)): #emoji-> í•œê¸€ ë³€í™˜
        if df.loc[i,'lang']=='ko':
            temp = df.loc[i,'processed_content']
            demoji_text = emoji.demojize(temp, language = 'ko')
            demoji_list = {"â™¡" : "í•˜íŠ¸", "ğŸ«¶ğŸ»" : "í•˜íŠ¸",  "ğŸ«°ğŸ»" : "í•˜íŠ¸", "ğŸ«¶ğŸ½": "í•˜íŠ¸"} #emoji.demojizeê°€ ì²˜ë¦¬í•´ì£¼ì§€ ëª»í•˜ëŠ” ì´ëª¨ì§€ ì¶”ê°€ ì²˜ë¦¬
             
            for emoji_code, emoji_kor in demoji_list.items():
                demoji_text = demoji_text.replace(emoji_code, emoji_kor) 
            
            df.loc[i, 'demoji_text']=demoji_text

    return df


